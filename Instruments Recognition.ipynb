{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Instrument Recognition (Signals and Systems)\n",
    "This is an instrument recognition project based on IRMAS data set.\n",
    "## Define the IRMASDataset class"
   ],
   "id": "90ab5bcb4f8b3e98"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-22T04:14:57.126803Z",
     "start_time": "2024-11-22T04:14:57.119653Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "class IRMASDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None, max_len=22050*3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_paths (list): 音频文件路径列表。\n",
    "            labels (list): 对应的标签列表。\n",
    "            transform (callable, optional): 对输入数据的变换。\n",
    "            max_len (int): 固定音频长度（采样点数）。超过的部分截断，不足的部分填充。\n",
    "        \"\"\"\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.max_len = max_len\n",
    "        self.unique_labels = sorted(list(set(labels)))\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(self.unique_labels)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        y, sr = librosa.load(audio_path, sr=22050)  # IRMAS默认采样率为22.05kHz\n",
    "\n",
    "        # 固定长度\n",
    "        if len(y) > self.max_len:\n",
    "            y = y[:self.max_len]\n",
    "        else:\n",
    "            y = np.pad(y, (0, max(0, self.max_len - len(y))), 'constant')\n",
    "\n",
    "        # 提取MFCC特征\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "        mfcc = librosa.util.fix_length(mfcc, size=40, axis=1)  # 固定时间帧数\n",
    "\n",
    "        # 转置以适应CNN输入（channels, height, width）\n",
    "        mfcc = mfcc.T  # shape: (time_frames, n_mfcc)\n",
    "        mfcc = np.expand_dims(mfcc, axis=0)  # shape: (1, time_frames, n_mfcc)\n",
    "\n",
    "        if self.transform:\n",
    "            mfcc = self.transform(mfcc)\n",
    "        else:\n",
    "            mfcc = torch.tensor(mfcc, dtype=torch.float32)\n",
    "\n",
    "        label = self.label_to_idx[label]\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return mfcc, label"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataloader & Preprocess",
   "id": "6c62f81010f101a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T04:15:01.427589Z",
     "start_time": "2024-11-22T04:15:01.423026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 获取文件路径和标签\n",
    "def get_file_paths_and_labels(root_dir):\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(root_dir):\n",
    "        if filename.endswith('.wav'):\n",
    "            file_paths.append(os.path.join(root_dir, filename))\n",
    "            # 文件名格式: '01-violin-A-1.wav'\n",
    "            label = filename.split('-')[1]\n",
    "            labels.append(label)\n",
    "    return file_paths, labels\n",
    "\n",
    "# 加载训练和验证集\n",
    "train_dir = './IRMAS/IRMAS-TrainingData'\n",
    "val_dir = './IRMAS/IRMAS-TestingData-Part1'\n",
    "\n",
    "train_files, train_labels = get_file_paths_and_labels(train_dir)\n",
    "val_files, val_labels = get_file_paths_and_labels(val_dir)\n",
    "\n",
    "# 创建数据集\n",
    "train_dataset = IRMASDataset(train_files, train_labels)\n",
    "val_dataset = IRMASDataset(val_files, val_labels)\n",
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ],
   "id": "b8f4e751c4bdbb49",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CNN Model for MFCC Classification\n",
   "id": "ebeae2d569902950"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T04:15:04.034282Z",
     "start_time": "2024-11-22T04:15:04.027887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # 假设MFCC的时间帧数为40，经过3次池化（每次除以2），时间帧数约为5\n",
    "        # n_mfcc = 40，经过3次池化后约为5\n",
    "        self.fc1 = nn.Linear(128 * 5 * 5, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))  # [batch, 32, 110, 20]\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))  # [batch, 64, 55, 10]\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))  # [batch, 128, 27, 5]\n",
    "        x = x.view(x.size(0), -1)  # 展平\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "id": "2cda179a6d835eb3",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training & Verification\n",
   "id": "cef42ef6365db68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T04:15:42.172719Z",
     "start_time": "2024-11-22T04:15:42.062381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'使用设备: {device}')\n",
    "\n",
    "# 初始化模型\n",
    "num_classes = len(train_dataset.unique_labels)\n",
    "model = SimpleCNN(num_classes=num_classes).to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练参数\n",
    "num_epochs = 30\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    # 验证\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_all_preds = []\n",
    "    val_all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_all_preds.extend(preds.cpu().numpy())\n",
    "            val_all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader.dataset)\n",
    "    val_acc = accuracy_score(val_all_labels, val_all_preds)\n",
    "    val_f1 = f1_score(val_all_labels, val_all_preds, average='weighted')\n",
    "    val_precision = precision_score(val_all_labels, val_all_preds, average='weighted')\n",
    "    val_recall = recall_score(val_all_labels, val_all_preds, average='weighted')\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] '\n",
    "          f'Train Loss: {epoch_loss:.4f} Train Acc: {epoch_acc:.4f} | '\n",
    "          f'Val Loss: {val_loss:.4f} Val Acc: {val_acc:.4f} '\n",
    "          f'Val Precision: {val_precision:.4f} Val Recall: {val_recall:.4f} Val F1: {val_f1:.4f}')\n",
    "\n",
    "    # 保存最佳模型\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_irmas_cnn.pth')\n",
    "        print(f'最佳模型已保存，验证准确率: {best_val_acc:.4f}')"
   ],
   "id": "15aa4fcf0b415cb7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集文件数量: 6705\n",
      "训练集示例:\n",
      "文件: ./IRMAS/IRMAS-TrainingData/pia/[pia][cla]1346__3.wav, 标签: piano\n",
      "文件: ./IRMAS/IRMAS-TrainingData/pia/[pia][cla]1291__1.wav, 标签: piano\n",
      "文件: ./IRMAS/IRMAS-TrainingData/pia/[pia][jaz_blu]1490__3.wav, 标签: piano\n",
      "文件: ./IRMAS/IRMAS-TrainingData/pia/027__[pia][nod][cla]1398__2.wav, 标签: piano\n",
      "文件: ./IRMAS/IRMAS-TrainingData/pia/[pia][jaz_blu]1524__1.wav, 标签: piano\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 23\u001B[0m\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m文件: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_files[i]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, 标签: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_labels[i]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# 划分训练集和验证集\u001B[39;00m\n\u001B[0;32m---> 23\u001B[0m train_files, val_files, train_labels, val_labels \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_test_split\u001B[49m(\n\u001B[1;32m     24\u001B[0m     train_files,\n\u001B[1;32m     25\u001B[0m     train_labels,\n\u001B[1;32m     26\u001B[0m     test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m,\n\u001B[1;32m     27\u001B[0m     stratify\u001B[38;5;241m=\u001B[39mtrain_labels,\n\u001B[1;32m     28\u001B[0m     random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m\n\u001B[1;32m     29\u001B[0m )\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m训练集实际文件数量: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(train_files)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m验证集文件数量: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(val_files)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Evaluation\n",
   "id": "f5e8e7142d7ccef9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T04:15:33.562526Z",
     "start_time": "2024-11-22T04:15:33.536360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载最佳模型\n",
    "model = SimpleCNN(num_classes=num_classes).to(device)\n",
    "model.load_state_dict(torch.load('best_irmas_cnn.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 示例评估函数\n",
    "def evaluate(model, loader):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(loader, desc=\"Evaluating\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    print(f'Accuracy: {acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "\n",
    "# 评估验证集\n",
    "evaluate(model, val_loader)"
   ],
   "id": "f70b29eb427773d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集文件数量: 6705\n",
      "训练集示例:\n",
      "文件: ./IRMAS/IRMAS-TrainingData/pia/[pia][cla]1346__3.wav, 标签: piano\n",
      "文件: ./IRMAS/IRMAS-TrainingData/pia/[pia][cla]1291__1.wav, 标签: piano\n",
      "文件: ./IRMAS/IRMAS-TrainingData/pia/[pia][jaz_blu]1490__3.wav, 标签: piano\n",
      "文件: ./IRMAS/IRMAS-TrainingData/pia/027__[pia][nod][cla]1398__2.wav, 标签: piano\n",
      "文件: ./IRMAS/IRMAS-TrainingData/pia/[pia][jaz_blu]1524__1.wav, 标签: piano\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[13], line 24\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m文件: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_files[i]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, 标签: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_labels[i]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# 划分训练集和验证集\u001B[39;00m\n\u001B[0;32m---> 24\u001B[0m train_files, val_files, train_labels, val_labels \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_test_split\u001B[49m(\n\u001B[1;32m     25\u001B[0m     train_files,\n\u001B[1;32m     26\u001B[0m     train_labels,\n\u001B[1;32m     27\u001B[0m     test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m,\n\u001B[1;32m     28\u001B[0m     stratify\u001B[38;5;241m=\u001B[39mtrain_labels,\n\u001B[1;32m     29\u001B[0m     random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m\n\u001B[1;32m     30\u001B[0m )\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m训练集实际文件数量: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(train_files)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m验证集文件数量: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(val_files)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
